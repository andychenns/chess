---
title: "Chess Project Part 2"
author: "LonghaoChen&SenhWang"
date: "1/4/2022"
output: html_document
---

```{r setup, include=FALSE}
library(DBI)
library(dbplyr)
library(dplyr)
library(RSQLite)
library(tidyverse)
library(reshape2) 
setwd("/Users/longhaochen/chess/chess/Database/")
db <- dbConnect(SQLite(), dbname = "chess_project.db")
```


```{r}
dbListTables(db)

dbGetQuery(db, "SELECT * FROM Match LIMIT 5")

match <- tbl(db, "Match")

match %>%
  select(everything())

head(match, 5)
```

1. What opening are most common? In different level of players?

```{r}
# We are interested in the most popular opening for each rank of players.
common_opening <- dbGetQuery(db, "SELECT COUNT(*), opening, Rank FROM Match GROUP BY opening, Rank")

# First we sorted by most popular opening. We then wanted to know what the most popular opening is for each rank of players so that we can make the best opening recommendations for players to learn.
common_opening_2 <- match %>%
  select(ID, opening, Rank) %>%
  group_by(opening, Rank) %>%
  summarise(num_opening = n_distinct(ID)) %>%
  ungroup() %>%
  group_by(Rank) %>%
  mutate(popularity = dense_rank(desc(num_opening))) %>%
  arrange(desc(num_opening))

print(common_opening_2)

# Translates dplyr function to SQL query
show_query(match %>%
  select(ID, opening, Rank) %>%
  group_by(opening, Rank) %>%
  summarise(num_opening = n_distinct(ID)) %>%
  ungroup() %>%
  group_by(Rank) %>%
  mutate(popularity = dense_rank(desc(num_opening))) %>%
  arrange(desc(num_opening)))

# Visualize the result
result <- data.frame(common_opening_2) %>% filter(popularity <= 10)

l <- ggplot(result, aes(Rank, opening))
l + geom_tile(aes(fill = num_opening))
```
There are a few openings that are popular among all rank levels. For example, the Sicilian Defense and Scandinavian Defense: Mieses-Kotroc Variation openings are played by both beginners and experts. However, there also differences that we noticed. We can see that the Van\'t Kruijs Opening is popular among lower-ranked players and not as much among higher-ranked players. The Modern Defense and Indian Game openings are mostly played by experts and not by beginners.
Rank A: top 25% by Elo rating, Rank B: between 25-50% by Elo, Rank C: bottom 25-50% by Elo, Rank D: bottom 25% by Elo
num_opening is popularity of opening from greatest to least

2. What opening tends to end early (number of moves are low)?

```{r}
# First step is to sum up the steps in match_move. Then join the result with match. Last to group by different opening and level of players.


dbGetQuery(db, 'SELECT AVG(num_moves),COUNT(ID) as num_match,opening,rank FROM (SELECT FLOOR(COUNT(match_move.ID)/2) AS "num_moves", match_move.ID, match.rank, match.opening FROM Match_Move  join match on match_move.id = match.id GROUP BY match_move.id) GROUP BY opening, rank ORDER BY num_match desc')

# We used dplyr to find the average number of moves an opening takes by rank
match_move <- tbl(db, "Match_Move")
move <- inner_join(match %>% select(ID, opening, Rank), match_move %>% group_by(ID) %>% summarise(num_moves = floor(n() / 2)), by = "ID") %>%
  group_by(opening, Rank) %>%
  summarise(avg_num_moves = mean(num_moves), num_match = n()) %>%
  arrange(desc(num_match))

# Translate dplyr function to SQL
show_query(inner_join(match %>% select(ID, opening, Rank), match_move %>% group_by(ID) %>% summarise(num_moves = floor(n() / 2)), by = "ID") %>% group_by(opening, Rank) %>% summarise(avg_num_moves = mean(num_moves), num_match = n()) %>% arrange(desc(num_match)))
```

In order to find out whether the opening of a chess game will influence the number of move, we need to run a chi-square test. Basically, this tests whether the number of moves fall into various intervals is consistent across different opening with a normal distribution.

```{r}
#Create a df for chi square test
df <- data.frame(inner_join(match %>% select(ID, opening, Rank), match_move %>% group_by(ID) %>% summarise(num_moves = floor(n() / 2)), by = "ID"))

#Add number of move interval
df$interval <- floor(df$num_moves/5) + 1

#Cast df to wide format
df_W = dcast(df, opening~interval) 

#Run chi-square test

chisq <- chisq.test(df_W[,-1])
chisq

# Expected counts
round(chisq$expected,2)
chisq$observed
```

The small P-value indicates that we can reject the null hypothesis that there is no relationship between opening and length of the game.


3. Give me a table so I can analyze the relationship between time usage (seconds) and eval? Our null hypothesis is that if a player spend significant more time on a single move, the evaluation will improve!

Evaluation system given from Li-Chess
```{r}
dbGetQuery(db, "SELECT CAST(eval AS text), * FROM Match_move where substr(CAST(eval AS text),1,1) == '#'")
```

1. Create a column to identify whether it is white or black player
```{r}
match_move %<>%
  group_by(ID) %>%
  mutate(player = row_number() %% 2)

head(match_move, 5)
```

2. Strategically, we focus our analysis on the early and mid game. For matches that developed into late stage, we will ignore them. Here the definition of late stage is when one play holds great advantage against the other one. When this happen, the evaluation system will have a "#" tag, which means the number of steps away from check mate. We will filter out any part after the "#" tag is detected.

```{r}
#dbGetQuery(db, "CREATE VIEW hash_only AS SELECT * FROM Match_move where Eval LIKE '#%'")
#dbGetQuery(db, "CREATE VIEW num_only AS SELECT * FROM Match_move where Eval NOT LIKE '#%'")

#Below query creates a column for the step number
# dbGetQuery(db,"SELECT ID, Move, CAST(eval AS text),  Seconds,  row_number() OVER (PARTITION BY ID) GROUPSEQ
# FROM Match_move")
# 
# #Create a column for step number on the table
# match_move %<>%
#   group_by(ID) %>%
#   mutate(steps = row_number() )
# 
# dbGetQuery(db,"CREATE VIEW match_steps AS SELECT * FROM match_move")
# match_move_df <- as.data.frame(match_move)
# dbWriteTable(db, "match_steps", match_move_df)

#To continue, we will find the step number where the first "#" is detected and filter out steps after # in each game.

# match_no_hashtag <- dbGetQuery(db,"SELECT t1.rowid, t1.ID, t1.eval, t1.Seconds, t1.move, t1.clock
# FROM Match_Move AS t1
# LEFT OUTER JOIN Match_Move AS t2
#   ON t1.rowid >= t2.rowid AND t1.ID = t2.ID AND (SELECT SUBSTR(t2.eval, 1, 1) AS ExtractString from Match_Move) = '#'
# WHERE t2.rowid IS NULL")

save(match_no_hashtag, file = "match_no_hashtag.RData")

```

3. Calculate the evaluation difference using lag function similar to how we calculate time usage

```{r}
# Calculate time spent difference. 0 for player is white, 1 is black
match_no_hashtag %<>%
  group_by(ID) %>%
  mutate(player = row_number() %% 2)

# Calculate time use for each move by taking the difference between time left of current move and previous move for both players
match_no_hashtag %<>%
  group_by(ID, player) %>%
  mutate(time_use = lag(Seconds) - Seconds)

# Calculate evaluation difference by taking the difference between eval of current move and previous move for both players
match_no_hashtag %<>%
  group_by(ID) %>%
  mutate(eval_dif = lead(Eval-lag(Eval)))
```

4. Visualize both time and eval
```{r}
#Start with a scatter point plot

e <- ggplot(match_no_hashtag[1:10000,], aes(time_use, eval_dif)) 

e + geom_point()

```
We see from the visualization above that most steps fall between -25 to 25 for eval_dif and 0 to 50 for time_use. There are also negative time_use which means times for players increased after each step. What we can take from this is that if a player thinks for a long time, they are more likely not to make a blunder but also not likely to improve. Also eval_dif is more volatile when a player takes less time because usually that means there is an obvious move after opponent made a mistake.

```{r}
# Filter out first 10 moves of each game. Beginning of the game is mostly memorized by players so we are not interested.
match_no_hashtag %<>%
  group_by(ID) %>%
  slice(21:n())

# Remove steps with time_use = 1 and eval_dif < 1. We want to narrow down our focus to moves that are more significant in order to give players useful advice when they review their games.
match_no_hashtag <- filter(match_no_hashtag, time_use != 1 & abs(eval_dif) < 1)

#Next step is to subset the data for steps that player think for a long time (the definition of long time is pending) and analyze the eval_diff



```

14. What is the winning percentage of white? Also what is the percentage of games that end in draw? In different openings.
